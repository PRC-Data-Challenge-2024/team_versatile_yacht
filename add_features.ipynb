{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values \n",
    "# loading variables from .env file\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_data_folder=os.getenv(\"SOURCE_FOLDER\")\n",
    "challenge_file=os.getenv(\"CHALLENGE_FILE\")\n",
    "challenge_file_preproc=os.getenv(\"CHALLENGE_FILE_PREPROC\")\n",
    "submission_file=os.getenv(\"SUBMISSION_FILE\")\n",
    "submission_file_preproc=os.getenv(\"SUBMISSION_FILE_PREPROC\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(source_data_folder,challenge_file))\n",
    "df_submission = pd.read_csv(os.path.join(source_data_folder,submission_file))\n",
    "\n",
    "# Mapping of aircraft_type, and categories\n",
    "weight_class_mapping = {\n",
    "    'A332': 'Heavy', 'A333': 'Heavy', 'A343': 'Heavy',\n",
    "    'A359': 'Heavy', 'B772': 'Heavy', 'B773': 'Heavy',\n",
    "    'B77W': 'Heavy', 'B788': 'Heavy', 'B789': 'Heavy',\n",
    "    'B752': 'Heavy', 'B763': 'Heavy', 'A310': 'Heavy',\n",
    "    'A20N': 'Medium', 'A21N': 'Medium', 'A319': 'Medium', 'A320': 'Medium',\n",
    "    'A321': 'Medium', 'B738': 'Medium', 'B739': 'Medium', 'B38M': 'Medium',\n",
    "    'B39M': 'Medium', 'B737': 'Medium',\n",
    "    'BCS1': 'Light', 'BCS3': 'Light', 'CRJ9': 'Light', 'E190': 'Light',\n",
    "    'E195': 'Light', 'E290': 'Light', 'AT76': 'Light',\n",
    "    'C56X': 'Light'\n",
    "}\n",
    "\n",
    "# Add \"aircraft_category\" column\n",
    "df['aircraft_category'] = df['aircraft_type'].map(weight_class_mapping)\n",
    "df_submission['aircraft_category'] = df_submission['aircraft_type'].map(weight_class_mapping)\n",
    "\n",
    "# Check if all aircraft_type exist\n",
    "df_missing = df[df['aircraft_category'].isna()]\n",
    "if not df_missing.empty:\n",
    "    print(\"The following aircraft_types does not exist in mapping :\")\n",
    "    print(df_missing['aircraft_type'].unique())\n",
    "\n",
    "# Check if all aircraft_type exist\n",
    "df_sub_missing = df_submission[df_submission['aircraft_category'].isna()]\n",
    "if not df_sub_missing.empty:\n",
    "    print(\"The following aircraft_types does not exist in mapping :\")\n",
    "    print(df_sub_missing['aircraft_type'].unique())\n",
    "\n",
    "df.to_csv(os.path.join(source_data_folder,challenge_file_preproc), index=False)\n",
    "df_submission.to_csv(os.path.join(source_data_folder,submission_file_preproc), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load File\n",
    "df_aircraft = pd.read_csv(os.path.join(source_data_folder,os.getenv(\"AIRCRAFT_DB\")))\n",
    "df_test = pd.read_csv(os.path.join(source_data_folder,challenge_file_preproc))\n",
    "df_submission = pd.read_csv(os.path.join(source_data_folder,submission_file_preproc))\n",
    "\n",
    "# Mapping RECAT with aircraft_category\n",
    "recat_mapping = {\n",
    "    \"CAT-A\": \"Heavy\", \n",
    "    \"CAT-B\": \"Heavy\", \n",
    "    \"CAT-C\": \"Heavy\", \n",
    "    \"CAT-D\": \"Medium\", \n",
    "    \"CAT-E\": \"Light\", \n",
    "    \"CAT-F\": \"Light\"\n",
    "}\n",
    "\n",
    "# Update both files with RECAT\n",
    "def update_aircraft_info(df_target, df_aircraft):\n",
    "    for _, row in df_aircraft.iterrows():\n",
    "        aircraft_type = row['Aircraft_Type']\n",
    "        recat_value = row['RECAT-EU']\n",
    "        \n",
    "        # Chech if exists\n",
    "        mask = df_target['aircraft_type'] == aircraft_type\n",
    "        \n",
    "        # If exists, update file\n",
    "        if mask.any():\n",
    "            df_target.loc[mask, 'aircraft_category'] = recat_mapping.get(recat_value, df_target.loc[mask, 'aircraft_category'])\n",
    "            df_target.loc[mask, 'aircraft_OEW'] = row['Aircraft_OEW']\n",
    "            df_target.loc[mask, 'aircraft_ZFW'] = row['Aircraft_ZFW']\n",
    "            df_target.loc[mask, 'aircraft_max_range'] = row['Aircraft_MaxRange']\n",
    "    \n",
    "    return df_target\n",
    "\n",
    "df_test = update_aircraft_info(df_test, df_aircraft)\n",
    "df_submission = update_aircraft_info(df_submission, df_aircraft)\n",
    "\n",
    "# Save changes to file\n",
    "df_test.to_csv(os.path.join(source_data_folder,challenge_file_preproc), index=False)\n",
    "df_submission.to_csv(os.path.join(source_data_folder,submission_file_preproc), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTOW, OEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for CRJ9: Aircraft crj9 not available.\n",
      "Error for BCS3: Aircraft bcs3 not available.\n",
      "Error for AT76: Aircraft at76 not available.\n",
      "Error for BCS1: Aircraft bcs1 not available.\n",
      "Error for A310: Aircraft a310 not available.\n",
      "Error for C56X: Aircraft c56x not available.\n",
      "Error for E290: Aircraft e290 not available.\n",
      "The columns min_tow and max_tow have been added and saved in '/workspaces/PRCDataChallenge/data/challenge_set_preproc.csv'.\n",
      "Error for BCS3: Aircraft bcs3 not available.\n",
      "Error for CRJ9: Aircraft crj9 not available.\n",
      "Error for BCS1: Aircraft bcs1 not available.\n",
      "Error for AT76: Aircraft at76 not available.\n",
      "Error for E290: Aircraft e290 not available.\n",
      "The columns min_tow and max_tow have been added and saved in '/workspaces/PRCDataChallenge/data/submission_set_preproc.csv'.\n"
     ]
    }
   ],
   "source": [
    "from openap import prop\n",
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Iterate through each file\n",
    "for file in files:\n",
    "    # Load the CSV file\n",
    "    df_flight = pd.read_csv(file)\n",
    "\n",
    "    # List of unique aircraft types in the file\n",
    "    aircraft_types = df_flight['aircraft_type'].unique()\n",
    "\n",
    "    # Initialize a dictionary to store MTOW and OEW values\n",
    "    aircraft_data = {}\n",
    "\n",
    "    # Use the openap library to retrieve information for each aircraft\n",
    "    for aircraft_type in aircraft_types:\n",
    "        try:\n",
    "            # Get aircraft information via ICAO\n",
    "            aircraft = prop.aircraft(f'{aircraft_type}')\n",
    "            mtow = aircraft['mtow']\n",
    "            oew = aircraft['oew']\n",
    "            \n",
    "            # Store results in the dictionary\n",
    "            aircraft_data[aircraft_type] = {'max_tow': mtow, 'min_tow': oew}\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {aircraft_type}: {e}\")\n",
    "            aircraft_data[aircraft_type] = {'max_tow': None, 'min_tow': None}\n",
    "\n",
    "    # Add 'min_tow' and 'max_tow' columns to the DataFrame\n",
    "    df_flight['aircraft_OEW'] = df_flight['aircraft_type'].map(lambda x: aircraft_data.get(x, {}).get('min_tow', None))\n",
    "    df_flight['aircraft_MTOW'] = df_flight['aircraft_type'].map(lambda x: aircraft_data.get(x, {}).get('max_tow', None))\n",
    "\n",
    "    df_flight.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"The columns min_tow and max_tow have been added and saved in '{file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Create a dictionary with the values of aircraft_OEW and aircraft_MTOW\n",
    "tow_data = {\n",
    "    'CRJ9': {'aircraft_OEW': 21772, 'aircraft_MTOW': 38329},\n",
    "    'BCS3': {'aircraft_OEW': 37100, 'aircraft_MTOW': 70900},\n",
    "    'AT76': {'aircraft_OEW': 13311, 'aircraft_MTOW': 21000},\n",
    "    'A310': {'aircraft_OEW': 80000, 'aircraft_MTOW': 153000},\n",
    "    'BCS1': {'aircraft_OEW': 37500, 'aircraft_MTOW': 63100},\n",
    "    'C56X': {'aircraft_OEW': 5750, 'aircraft_MTOW': 9163},\n",
    "    'E290': {'aircraft_OEW': 27853, 'aircraft_MTOW': 56400},\n",
    "    'B763': {'aircraft_OEW': 95000, 'aircraft_MTOW': 187000},\n",
    "    'B737': {'aircraft_OEW': 39000, 'aircraft_MTOW': 79000},\n",
    "    'B788': {'aircraft_OEW': 118000, 'aircraft_MTOW': 228000},\n",
    "    'B789': {'aircraft_OEW': 127000, 'aircraft_MTOW': 254000}\n",
    "}\n",
    "\n",
    "# Iterate through each file\n",
    "for file in files:\n",
    "    # Load the CSV file\n",
    "    df_flight = pd.read_csv(file)\n",
    "\n",
    "    # Fill the 'aircraft_OEW' and 'aircraft_MTOW' columns based on aircraft_type\n",
    "    df_flight['aircraft_OEW'] = df_flight.apply(\n",
    "        lambda row: tow_data.get(row['aircraft_type'], {}).get('aircraft_OEW', row.get('aircraft_OEW')),\n",
    "        axis=1\n",
    "    )\n",
    "    df_flight['aircraft_MTOW'] = df_flight.apply(\n",
    "        lambda row: tow_data.get(row['aircraft_type'], {}).get('aircraft_MTOW', row.get('aircraft_MTOW')),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Save the modified file\n",
    "\n",
    "    df_flight.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"The columns 'aircraft_OEW' and 'aircraft_MTOW' have been updated for the corresponding aircraft types in '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio TOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "updated_tow_file=os.path.join(source_data_folder,challenge_file_preproc)\n",
    "df_flight = pd.read_csv(updated_tow_file)\n",
    "\n",
    "# Check if the columns 'tow', 'aircraft_OEW', and 'aircraft_MTOW' exist in the DataFrame\n",
    "if all(col in df_flight.columns for col in ['tow', 'aircraft_OEW', 'aircraft_MTOW']):\n",
    "    # Calculate the load_ratio according to the given formula\n",
    "    df_flight['load_ratio'] = (df_flight['tow'] - df_flight['aircraft_OEW']) / (df_flight['aircraft_MTOW'] - df_flight['aircraft_OEW'])\n",
    "    \n",
    "    # Save the modified file\n",
    "    df_flight.to_csv(updated_tow_file, index=False)\n",
    "    \n",
    "    print(\"The 'load_ratio' column has been added and saved to '{}'.\".format(updated_tow_file))\n",
    "else:\n",
    "    print(\"The columns 'tow', 'aircraft_OEW', or 'aircraft_MTOW' are missing in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "updated_tow_file=os.path.join(source_data_folder,submission_file_preproc)\n",
    "df_flight = pd.read_csv(updated_tow_file)\n",
    "\n",
    "df_flight['load_ratio'] = None\n",
    "\n",
    "df_flight.to_csv(updated_tow_file, index=False)\n",
    "\n",
    "print(\"The 'load_ratio' column has been added and saved to '{}'.\".format(updated_tow_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flown_distance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_file_preproc=updated_tow_file=os.path.join(source_data_folder,challenge_file_preproc)\n",
    "submission_file_preproc=updated_tow_file=os.path.join(source_data_folder,challenge_file_preproc)\n",
    "df_test = pd.read_csv(test_file_preproc)\n",
    "df_submission = pd.read_csv(submission_file_preproc)\n",
    "\n",
    "# Function to add the \"ratio_flown_distance_max_range\" column\n",
    "def add_flown_distance_ratio(df_target):\n",
    "    # Assume that 'flown_distance' and 'aircraft_max_range' exist\n",
    "    df_target['ratio_flown_distance_max_range'] = df_target['flown_distance'] / df_target['aircraft_max_range']\n",
    "    return df_target\n",
    "\n",
    "# Add the \"ratio_flown_distance_max_range\" column\n",
    "df_test = add_flown_distance_ratio(df_test)\n",
    "df_submission = add_flown_distance_ratio(df_submission)\n",
    "\n",
    "# Save the modifications to the CSV files\n",
    "df_test.to_csv(test_file_preproc, index=False)\n",
    "df_submission.to_csv(submission_file_preproc, index=False)\n",
    "\n",
    "print(\"\\nThe modified files have been saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode / Max / Median altitude and cruise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "altitude_data = pd.read_csv(os.path.join(source_data_folder,os.getenv(\"TRAJECTORY_DATA\")))\n",
    "challenge_set_og = pd.read_csv(test_file_preproc)\n",
    "final_submission_set = pd.read_csv(submission_file_preproc)\n",
    "\n",
    "# Merge altitude_data with challenge_set_og on flight_id\n",
    "merged_challenge_set = pd.merge(\n",
    "    challenge_set_og,\n",
    "    altitude_data[['flight_id','fl_mode','fl_max','fl_median', 'plateau_climb_rate_avg', 'plateau_altitude']],\n",
    "    on='flight_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge altitude_data with final_submission_set on flight_id\n",
    "merged_final_submission_set = pd.merge(\n",
    "    final_submission_set,\n",
    "    altitude_data[['flight_id', 'fl_mode','fl_max','fl_median','plateau_climb_rate_avg', 'plateau_altitude']],\n",
    "    on='flight_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Save the results to new CSV files\n",
    "merged_challenge_set.to_csv(test_file_preproc, index=False)\n",
    "merged_final_submission_set.to_csv(submission_file_preproc, index=False)\n",
    "\n",
    "print(\"\\nThe files have been merged and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combo Adep / Ades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_flight = pd.read_csv(file)\n",
    "\n",
    "    # Create a new column 'adep_ades' that combines 'adep' and 'ades'\n",
    "    df_flight['adep_ades'] = df_flight[['adep', 'ades']].apply(lambda x: f'{x[0]}_{x[1]}', axis=1)\n",
    "\n",
    "    # Assign a unique numeric value to each 'adep_ades' combination\n",
    "    df_flight['adep_ades'] = pd.factorize(df_flight['adep_ades'])[0]\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df_flight.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file} with new 'adep_ades' column.\")\n",
    "\n",
    "print(\"All files have been updated with the new 'adep_ades' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Circle distance Adep / Ades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from traffic.data import airports\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Function to calculate great circle distance\n",
    "def calculate_great_circle_distance(row, adep_latlon, ades_latlon):\n",
    "    adep_coords = adep_latlon.get(row['adep'], None)\n",
    "    ades_coords = ades_latlon.get(row['ades'], None)\n",
    "    if adep_coords and ades_coords:\n",
    "        return great_circle(adep_coords, ades_coords).kilometers\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Get unique departure and arrival airport codes\n",
    "    unique_adeps = df['adep'].unique()\n",
    "    unique_ades = df['ades'].unique()\n",
    "\n",
    "    # Create dictionaries to store lat/lon of airports\n",
    "    adep_latlon = {}\n",
    "    ades_latlon = {}\n",
    "\n",
    "    # Retrieve lat/lon for unique departure airports\n",
    "    for adep in unique_adeps:\n",
    "        try:\n",
    "            airport = airports[adep]\n",
    "            adep_latlon[adep] = airport.latlon\n",
    "        except ValueError:\n",
    "            adep_latlon[adep] = None\n",
    "\n",
    "    # Retrieve lat/lon for unique arrival airports\n",
    "    for ades in unique_ades:\n",
    "        try:\n",
    "            airport = airports[ades]\n",
    "            ades_latlon[ades] = airport.latlon\n",
    "        except ValueError:\n",
    "            ades_latlon[ades] = None\n",
    "\n",
    "    # Calculate great circle distances\n",
    "    df['great_circle_distance_adep_ades'] = df.apply(calculate_great_circle_distance, axis=1, \n",
    "                                                      args=(adep_latlon, ades_latlon))\n",
    "\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file} with great circle distances.\")\n",
    "\n",
    "print(\"Great circle distances have been calculated and saved for all files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flown_distance / Great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Convert flown_distance from nautical miles to kilometers\n",
    "    # 1 nautical mile = 1.852 kilometers\n",
    "    df['flown_distance_km'] = df['flown_distance'] * 1.852\n",
    "\n",
    "    # Calculate the great circle flown distance\n",
    "    df['great_circle_flown_distance'] = df['flown_distance_km'] / df['great_circle_distance_adep_ades']\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file} with new 'flown_distance_km' and 'great_circle_flown_distance' columns.\")\n",
    "\n",
    "print(\"All files have been updated with the new calculations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average_speed ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Function to calculate new columns based on time data\n",
    "def calculate_takeoff_time_duration(df):\n",
    "    # 1. Calculate takeoff_time (actual_offblock_time + taxiout_time)\n",
    "    df['takeoff_time'] = df['actual_offblock_time'] + pd.to_timedelta(df['taxiout_time'], unit='m')\n",
    "\n",
    "    # 2. Calculate duration in minutes (arrival_time - takeoff_time)\n",
    "    df['duration'] = (df['arrival_time'] - df['takeoff_time']).dt.total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "    # 3. Calculate average_speed (flown_distance / duration)\n",
    "    df['average_speed'] = (df['flown_distance'] / df['duration']) * 60  # Convert to nautical miles per hour\n",
    "\n",
    "    df['average_speed'] = df['average_speed'] ** 2\n",
    "\n",
    "    return df\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Convert date columns to datetime format\n",
    "    df['actual_offblock_time'] = pd.to_datetime(df['actual_offblock_time'])\n",
    "    df['arrival_time'] = pd.to_datetime(df['arrival_time'])\n",
    "\n",
    "    # Apply the calculations to the DataFrame\n",
    "    df = calculate_takeoff_time_duration(df)\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file} with new columns.\")\n",
    "\n",
    "print(\"All files have been updated with new columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage offblock time and arrival time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Function to determine the season based on the month\n",
    "def determine_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 1  # Winter\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 2  # Spring\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 3  # Summer\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 4  # Autumn\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Read the file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Ensure the 'actual_offblock_time' and 'arrival_time' columns are in datetime format\n",
    "    df['actual_offblock_time'] = pd.to_datetime(df['actual_offblock_time'])\n",
    "    df['arrival_time'] = pd.to_datetime(df['arrival_time'])\n",
    "\n",
    "    # Extract month, day, and hour from actual_offblock_time\n",
    "    df['month_offblock_time'] = df['actual_offblock_time'].dt.month\n",
    "    df['day_offblock_time'] = df['actual_offblock_time'].dt.day\n",
    "    df['hour_offblock_time'] = df['actual_offblock_time'].dt.hour\n",
    "\n",
    "    # Extract month, day, and hour from arrival_time\n",
    "    df['month_arrival_time'] = df['arrival_time'].dt.month\n",
    "    df['day_arrival_time'] = df['arrival_time'].dt.day\n",
    "    df['hour_arrival_time'] = df['arrival_time'].dt.hour\n",
    "\n",
    "    # Apply the function to create the 'season' column\n",
    "    df['season'] = df['month_offblock_time'].apply(determine_season)\n",
    "\n",
    "    # Save the modified DataFrame back to the same file\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "print(\"The season, month, day, and hour columns have been added and saved to both files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Read the data\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Ensure the 'actual_offblock_time' column is in datetime format\n",
    "    df['actual_offblock_time'] = pd.to_datetime(df['actual_offblock_time'])\n",
    "\n",
    "    # Extract the hour from the 'actual_offblock_time' column\n",
    "    df['hour_offblock_time'] = df['actual_offblock_time'].dt.hour\n",
    "\n",
    "    # Define a function to assign the time of day period\n",
    "    def determine_day_period(hour):\n",
    "        if hour < 9:\n",
    "            return 1  # Before 9 AM\n",
    "        elif 9 <= hour <= 16:\n",
    "            return 2  # Between 9 AM and 4 PM\n",
    "        else:\n",
    "            return 3  # After 4 PM\n",
    "\n",
    "    # Apply this function to create the 'day_period' column\n",
    "    df['day_period'] = df['hour_offblock_time'].apply(determine_day_period)\n",
    "\n",
    "    # Save the file with the new column\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file}\")\n",
    "\n",
    "print(\"The 'hour_offblock_time' and 'day_period' columns have been added and saved to both files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aircraft range category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Define a function to assign distance intervals\n",
    "def get_flown_distance_interval(distance):\n",
    "    if distance < 500:\n",
    "        return \"0-500\"\n",
    "    elif 500 <= distance < 1000:\n",
    "        return \"500-1000\"\n",
    "    elif 1000 <= distance < 1500:\n",
    "        return \"1000-1500\"\n",
    "    elif 1500 <= distance < 2000:\n",
    "        return \"1500-2000\"\n",
    "    elif 2000 <= distance < 4000:\n",
    "        return \"2000-4000\"\n",
    "    else:\n",
    "        return \"4000+\"\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Read the flight data\n",
    "    df_flight = pd.read_csv(file)\n",
    "\n",
    "    # Apply the function to create the flown_distance_interval column\n",
    "    df_flight['range_category'] = df_flight['flown_distance'].apply(get_flown_distance_interval)\n",
    "\n",
    "    # Use LabelEncoder to create the range_category_encoded column\n",
    "    le = LabelEncoder()\n",
    "    df_flight['range_category_encoded'] = le.fit_transform(df_flight['range_category'])\n",
    "\n",
    "    # Save the modified DataFrame back to the same file\n",
    "    df_flight.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Updated file: {file}\")\n",
    "\n",
    "print(\"The 'range_category' and 'range_category_encoded' columns have been added and saved to both files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOBT seconds and days, with sinus/cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [os.path.join(source_data_folder,challenge_file_preproc), os.path.join(source_data_folder,submission_file_preproc)]\n",
    "\n",
    "# Loop through each file\n",
    "for file in files_to_process:\n",
    "    # Load the flight data from the CSV file into a DataFrame\n",
    "    df_flight = pd.read_csv(file)\n",
    "\n",
    "    # Convert the 'actual_offblock_time' column to datetime format\n",
    "    df_flight['actual_offblock_time_dt'] = pd.to_datetime(df_flight['actual_offblock_time'])\n",
    "\n",
    "    # Calculate the number of seconds since the start of the day for 'actual_offblock_time'\n",
    "    df_flight['aobt_seconds'] = (df_flight['actual_offblock_time_dt'] - df_flight['actual_offblock_time_dt'].dt.normalize()) / pd.Timedelta('1 second')\n",
    "\n",
    "    # Compute the cosine of the seconds since the start of the day for cyclic feature representation\n",
    "    df_flight['aobt_seconds_cos'] = np.cos(df_flight['aobt_seconds'] * (np.pi * 2 / (3600 * 24)))\n",
    "\n",
    "    # Compute the sine of the seconds since the start of the day for cyclic feature representation\n",
    "    df_flight['aobt_seconds_sin'] = np.sin(df_flight['aobt_seconds'] * (np.pi * 2 / (3600 * 24)))\n",
    "\n",
    "    # Calculate the number of days since a reference date (January 1, 2022) for 'actual_offblock_time'\n",
    "    df_flight['aobt_days'] = (df_flight['actual_offblock_time_dt'] - pd.to_datetime(\"2022-01-01 00:00+00\")) / pd.Timedelta('1 day')\n",
    "\n",
    "    # Compute the cosine of the days since the reference date for cyclic feature representation\n",
    "    df_flight['aobt_days_cos'] = np.cos(df_flight['aobt_days'] * (np.pi * 2 / (365)))\n",
    "\n",
    "    # Compute the sine of the days since the reference date for cyclic feature representation\n",
    "    df_flight['aobt_days_sin'] = np.sin(df_flight['aobt_days'] * (np.pi * 2 / (365)))\n",
    "\n",
    "    # Save the modified DataFrame back to the same CSV file\n",
    "    df_flight.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"Processed and saved: {file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add ICAO code, and ICAO couple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the files\n",
    "utc_file =  os.path.join(source_data_folder,os.getenv(\"UTC_OFFSET\"))\n",
    "\n",
    "file_1 = os.path.join(source_data_folder,challenge_file_preproc)\n",
    "file_2 = os.path.join(source_data_folder,submission_file_preproc)\n",
    "\n",
    "utc_df = pd.read_csv(utc_file)\n",
    "df1 = pd.read_csv(file_1)\n",
    "df2 = pd.read_csv(file_2)\n",
    "\n",
    "# Merge with the 'UtcToLocalTimeOffset.csv' file to obtain 'ICAO_prefix' based on 'country_code_adep'\n",
    "df1_merged = pd.merge(df1, utc_df[['country_code_adep', 'ICAO_prefix']], left_on='country_code_adep', right_on='country_code_adep', how='left')\n",
    "df2_merged = pd.merge(df2, utc_df[['country_code_adep', 'ICAO_prefix']], left_on='country_code_adep', right_on='country_code_adep', how='left')\n",
    "\n",
    "# Rename the column 'ICAO_prefix' to 'country_code_adep_icao'\n",
    "df1_merged.rename(columns={'ICAO_prefix': 'country_code_adep_icao'}, inplace=True)\n",
    "df2_merged.rename(columns={'ICAO_prefix': 'country_code_adep_icao'}, inplace=True)\n",
    "\n",
    "# Add the column \"country_code_ades_icao\" based on \"ades\" and their corresponding ICAO code\n",
    "df1_merged = pd.merge(df1_merged, utc_df[['country_code_adep', 'ICAO_prefix']], left_on='country_code_ades', right_on='country_code_adep', how='left')\n",
    "df2_merged = pd.merge(df2_merged, utc_df[['country_code_adep', 'ICAO_prefix']], left_on='country_code_ades', right_on='country_code_adep', how='left')\n",
    "\n",
    "# Rename the second column 'ICAO_prefix' to 'country_code_ades_icao'\n",
    "df1_merged.rename(columns={'ICAO_prefix': 'country_code_ades_icao'}, inplace=True)\n",
    "df2_merged.rename(columns={'ICAO_prefix': 'country_code_ades_icao'}, inplace=True)\n",
    "\n",
    "# Remove duplicate columns after the merge\n",
    "df1_merged.drop(columns=['country_code_adep_y'], inplace=True)\n",
    "df2_merged.drop(columns=['country_code_adep_y'], inplace=True)\n",
    "\n",
    "# Save the updated files\n",
    "df1_merged.to_csv(file_1, index=False)\n",
    "df2_merged.to_csv(file_2, index=False)\n",
    "\n",
    "print(\"The updated files have been saved with the columns 'country_code_adep_icao' and 'country_code_ades_icao'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the cleaned files\n",
    "file_1 = os.path.join(source_data_folder,challenge_file_preproc)\n",
    "file_2 = os.path.join(source_data_folder,submission_file_preproc)\n",
    "\n",
    "df1 = pd.read_csv(file_1)\n",
    "df2 = pd.read_csv(file_2)\n",
    "\n",
    "# Function to generate the 'country_code_icao_couple' column\n",
    "def create_icao_couple(row):\n",
    "    adep_first_letter = str(row['country_code_adep_icao'])[0] if pd.notna(row['country_code_adep_icao']) else ''\n",
    "    ades_first_letter = str(row['country_code_ades_icao'])[0] if pd.notna(row['country_code_ades_icao']) else ''\n",
    "    \n",
    "    # Sort the letters in alphabetical order\n",
    "    sorted_letters = ''.join(sorted([adep_first_letter, ades_first_letter]))\n",
    "    return sorted_letters\n",
    "\n",
    "# Apply the function on both files\n",
    "df1['country_code_icao_couple'] = df1.apply(create_icao_couple, axis=1)\n",
    "df2['country_code_icao_couple'] = df2.apply(create_icao_couple, axis=1)\n",
    "\n",
    "# Save the files with the new column\n",
    "df1_merged.to_csv(file_1, index=False)\n",
    "df2_merged.to_csv(file_2, index=False)\n",
    "\n",
    "print(\"The files have been updated with the 'country_code_icao_couple' column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files into DataFrames\n",
    "airport_db = pd.read_csv('./database/MyAirportDatabase-V2.csv')\n",
    "runways_db = pd.read_csv('./database/runways.csv')\n",
    "\n",
    "# Merge the two DataFrames on the 'airport' and 'airport_ident' columns\n",
    "merged_df = pd.merge(airport_db, runways_db[['airport_ident', 'length_ft']], \n",
    "                     left_on='airport', right_on='airport_ident', \n",
    "                     how='left', suffixes=('', '_runway'))\n",
    "\n",
    "# Fill the 'MinRWYlength' column with values from 'length_ft'\n",
    "merged_df['MinRWYlength'] = merged_df['length_ft']\n",
    "\n",
    "# Drop the intermediate 'length_ft' and 'airport_ident' columns if necessary\n",
    "merged_df.drop(columns=['length_ft', 'airport_ident'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "merged_df.to_csv('./database/MyAirportDatabase_Updated.csv', index=False)\n",
    "\n",
    "print(\"The 'MinRWYlength' column has been updated with runway lengths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the updated file into a DataFrame\n",
    "updated_airport_db = pd.read_csv('./database/MyAirportDatabase_Updated.csv')\n",
    "\n",
    "# Check if the 'Taxi_In' column exists\n",
    "if 'Taxi_In' in updated_airport_db.columns:\n",
    "    # Create the new column 'taxi_in_seconds'\n",
    "    updated_airport_db['taxi_in_seconds'] = updated_airport_db['Taxi_In'] * 60\n",
    "\n",
    "    # Save the modified DataFrame back to the same CSV file\n",
    "    updated_airport_db.to_csv('./database/MyAirportDatabase_Updated.csv', index=False)\n",
    "\n",
    "    print(\"The 'taxi_in_seconds' column has been added successfully.\")\n",
    "else:\n",
    "    print(\"The 'Taxi_In' column does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the files into DataFrames\n",
    "final_submission = pd.read_csv('./final_submission_set.csv')\n",
    "challenge_set = pd.read_csv('./challenge_set_test_2.csv')\n",
    "\n",
    "# Load the file with the 'taxi_in_seconds' column\n",
    "airport_db = pd.read_csv('./database/MyAirportDatabase_Updated.csv')\n",
    "\n",
    "# Check if the 'taxi_in_seconds' column exists\n",
    "if 'taxi_in_seconds' in airport_db.columns:\n",
    "    # Remove duplicates while keeping the first occurrence of each airport\n",
    "    airport_db_unique = airport_db[['airport', 'taxi_in_seconds']].drop_duplicates(subset='airport')\n",
    "\n",
    "    # Add taxi_in_seconds to the final_submission file\n",
    "    final_submission_merged = pd.merge(final_submission, airport_db_unique, \n",
    "                                        left_on='ades', right_on='airport', \n",
    "                                        how='left', suffixes=('', '_airport'))\n",
    "\n",
    "    # Add taxi_in_seconds to the challenge_set_test_2 file\n",
    "    challenge_set_merged = pd.merge(challenge_set, airport_db_unique, \n",
    "                                     left_on='ades', right_on='airport', \n",
    "                                     how='left', suffixes=('', '_airport'))\n",
    "\n",
    "    # Save the modified files\n",
    "    final_submission_merged.to_csv('./final_submission_set_updated.csv', index=False)\n",
    "    challenge_set_merged.to_csv('./challenge_set_test_2_updated.csv', index=False)\n",
    "\n",
    "    print(\"The 'taxi_in_seconds' columns have been added to the files successfully.\")\n",
    "else:\n",
    "    print(\"The 'taxi_in_seconds' column does not exist in the airport DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the files into DataFrames\n",
    "final_submission = pd.read_csv('./final_submission_set.csv')  # Make sure to use the updated files\n",
    "challenge_set = pd.read_csv('./challenge_set_test_2.csv')\n",
    "\n",
    "# Define a function to calculate taxi_in\n",
    "def calculate_taxi_in(row):\n",
    "    if row['aircraft_category'] == 'Heavy':\n",
    "        return row['taxi_in_seconds'] * 0.3\n",
    "    elif row['aircraft_category'] == 'Medium':\n",
    "        return row['taxi_in_seconds'] * 0.2\n",
    "    elif row['aircraft_category'] == 'Light':\n",
    "        return row['taxi_in_seconds'] * 0.1\n",
    "    else:\n",
    "        return None  # Default value if no condition is met\n",
    "\n",
    "# Apply the function to create the taxi_in column\n",
    "final_submission['taxi_in'] = final_submission.apply(calculate_taxi_in, axis=1)\n",
    "challenge_set['taxi_in'] = challenge_set.apply(calculate_taxi_in, axis=1)\n",
    "\n",
    "# Save the modified files\n",
    "final_submission.to_csv('./final_submission_set_with_taxi_in.csv', index=False)\n",
    "challenge_set.to_csv('./challenge_set_test_2_with_taxi_in.csv', index=False)\n",
    "\n",
    "print(\"The 'taxi_in' column has been added successfully to the files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runway_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the files into DataFrames\n",
    "final_submission = pd.read_csv('./final_submission_set.csv')  # Use the updated file\n",
    "challenge_set = pd.read_csv('./challenge_set_test_2.csv')\n",
    "\n",
    "# Load the file with MinRWYlength to get the runway lengths\n",
    "airport_db = pd.read_csv('./database/MyAirportDatabase_Updated.csv')\n",
    "\n",
    "# Extract the first non-null value of MinRWYlength for each airport\n",
    "min_rwy_length_mapping = airport_db.groupby('airport')['MinRWYlength'].first().dropna()\n",
    "\n",
    "# Convert runway length from feet to kilometers\n",
    "min_rwy_length_mapping_km = min_rwy_length_mapping * 0.0003048  # 1 foot = 0.0003048 km\n",
    "\n",
    "# Create a new column runway_length in the DataFrames using the mapping\n",
    "final_submission['runway_length'] = final_submission['ades'].map(min_rwy_length_mapping_km)\n",
    "challenge_set['runway_length'] = challenge_set['ades'].map(min_rwy_length_mapping_km)\n",
    "\n",
    "# Save the modified files\n",
    "final_submission.to_csv('./final_submission_set_with_runway_length.csv', index=False)\n",
    "challenge_set.to_csv('./challenge_set_test_2_with_runway_length.csv', index=False)\n",
    "\n",
    "print(\"The 'runway_length' column has been added successfully to the files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low_cost Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers\n",
    "final_submission = pd.read_csv(\"./final_submission_set.csv\")\n",
    "challenge_set_test = pd.read_csv(\"./challenge_set_test_2.csv\")\n",
    "low_cost_airports = pd.read_csv(\"./database/low-cost_Airports_Europe.csv\")\n",
    "\n",
    "# Obtenir la liste des codes ICAO des aéroports à bas coûts\n",
    "low_cost_icao_codes = set(low_cost_airports['ICAO Code'].dropna())\n",
    "\n",
    "# Fonction pour attribuer 1 ou 0 à low_cost_airport\n",
    "def assign_low_cost_airport(row):\n",
    "    if row['adep'] in low_cost_icao_codes or row['ades'] in low_cost_icao_codes:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Appliquer la fonction à chaque fichier\n",
    "final_submission['low_cost_airport'] = final_submission.apply(assign_low_cost_airport, axis=1)\n",
    "challenge_set_test['low_cost_airport'] = challenge_set_test.apply(assign_low_cost_airport, axis=1)\n",
    "\n",
    "# Enregistrer les fichiers modifiés\n",
    "final_submission.to_csv(\"./final_submission_set_1.csv\", index=False)\n",
    "challenge_set_test.to_csv(\"./challenge_set_test_2_1.csv\", index=False)\n",
    "\n",
    "print(\"Colonnes 'low_cost_airport' ajoutées et fichiers sauvegardés.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
